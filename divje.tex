\chapter{Supporting Hands-on Design and Fabrication in a Real World Context}
My work starts with addressing how fabrication can be done closely integrated and attached to existing objects (Chapter 3), which then suggests a class of adaptation design where extra components can be made to enhance or modify functionalities of existing objects for custom usage (Chapter 4). Whether it is something add-on or standalone, functionality decides the form of objects; however, it can also be combined with people's intuitive creation through a mixed-initiative approach (Chapter 5). Ultimately, my goal is involve real people not just in the digital design process, but also in the physical making of objects that can functionally fulfill real world use cases. In this chapter, my focus bring fabrication even closer to reality by enabling design and fabrication to happen directly in the real world context in which they will eventually be put to use.

As mentioned in the earlier chapters, there is a lack of people's involvement in the actual making process, preventing them from participating in the realization of their design in a tighter feedback loop. With a hands-on approach, not only can people get better control of the making process, they can also develop their manual dexterity and, when successfully making something, get to experience the joy of it.

However, hands-on making---in its traditional sense---is not meant for everyone. Foremost, people's manual dexterity is different, which inherently adds various difficulties to the making process---making ceramics on a turntable is a familiar scenario wherein one's dexterity is often challenged. Further, even for dexterous people, without some sort of training it might also be difficult to perform making tasks, such as wood working. However, even for trained and experienced makers, to execute a making task would still from time to time require some external help, such as the need to refer to the design blue print or assembly instructions. Variance in dexterity, lack of skills and knowledge, and availability of information seem to be the major factors that would prevent or discourage people from getting themselves involved in the actual fabrication process.

\textbf{Leveraging Augmented Reality as solution to support human-centered making}. To overcome the intrinsic limitations of us as humans, we can leverage technology that can be designed and engineered to facilitate the making tasks. Specifically, the recent advances in Augmented Reality (AR) suggest opportunities of introducing them into the fabrication process.

AR has its own field of research that dated back to 1980's; a full review of its literature is beyond the scope of this thesis, as my focus is not on innovating AR, but rather to discover its combination with fabrication, and how to introduce aspects of AR in ways that would benefit existing design and fabrication process. As such, my review on AR aims at providing a brief background covering the basic understanding of the concept and the field, and then steering towards key literature that has explored the use of AR in creating or assembling physical objects.

The concept of AR is to situate digital information and computing system in the context of real world activity, rather than always behind a display. In this way computer users will experience a \textit{reality} that is \textit{augmented} with computing. One of the earliest papers that illustrated this concept is Feiner and Shamash's hybrid user interfaces \cite{feiner1991hybrid}: by stretching information display from a bounded screen space to its surrounding physical world, they increase the space for users to process and interact with such information. In Milgram and Kishino's taxonomy, AR belongs to a full spectrum of 'Mixed Reality': Real Environment---Augmented Reality---Augmented Virtuality---Virtual Environment \cite{milgram1994taxonomy}. Another early example of AR is Bajura et al.'s visualization of live ultrasound echography data `within' a human subject \cite{bajura1992merging}. Using a head-mounted camera, the generated 2D ultrasound images can be properly transformed to the observerâ€™s current viewing position. Edwards et al. describe the design and engineering of a head mounted display, from capturing stereoscopic views of the physical space, to projecting images to the display screens, to different mounting schemes and designs of camera lenses \cite{edwards1993video}. Rekimoto introduces a systematic way of annotating real world objects with tags readable by a handheld or wearable computer with a camera \cite{rekimoto1995world}. Using this system, people can see `the world through computer'---a world that can be overlaid with useful and contextual information.

Specifically related to physical tasks, prior work has explored using AR to facilitate collocated, collaborative design, such as Rekimoto's Transivision system \cite{rekimoto1996transvision}. To support the actual making or assembly process, researchers from Boeing built a heads-up see-through display to assist aircraft manufacturing tasks, thus eliminating the need of templates, formboard diagrams and other masking devices \cite{caudell1992augmented}. Reiners et al. developed an Augmented Reality demonstrator for the task of doorlock assembly into a car door \cite{reiners1998augmented}. In order to facilitate this task, their system was equipped with a fast and robust optical tracking algorithm integrated into 3D animation and rendering; instructions were communicated to the user through a head mounted display based application. Boud et al. investigated using AR in combination with VR (virtual reality) for training of manual skills \cite{boud1999virtual}. Tang et al. also performed a comparative study on the effectiveness between AR and traditional printed and externally displayed instructions \cite{tang2003comparative}. They found that using AR greatly reduced errors in assembly tasks and also resulted in less mental demand for the workers. Schwald and De Laval developed an AR-based system for maintaining equipment in industrial context \cite{schwald2003augmented}. Yuan et al. superimposed a virtual interaction panel during assembly tasks for retrieving instructions \cite{yuan2005assembly}. All this prior work almost exclusively focuses on AR-assisted assembly or maintenance tasks, in which the users' tasks are pre-defined with a limited scope and the system is primarily feeding them with textual or imagery instructions. A variety of new fabrication technology has emerged since the dates of this work and there is need for exploring new roles of AR in facilitating these processes to promote hands-on making tasks by real people.

 The recent advancement of wearable AR devices (e.g., Microsoft HoloLens\footnote{\url{https://www.microsoft.com/microsoft-hololens/en-us}}) provides an ideal platform for introducing AR into people's fabrication tasks, as the device can be unobtrusively worn, and can superimpose relevant information onto the physical environment, guiding or informing people of their making tasks at hand.

\textbf{In-situ digital fabrication scenario}. In Chapter 5, it has become apparent that a digital design need to address real world requirements such as what objects it needs to support, how much space it needs to create for placing these objects, and where it will be situated or installed. Although Mashup employs a mixed-initiative approach to help a user achieve a functional valid design, it still remains as a simulation based process that is intrinsically detached from the real world. In this project, by bringing the design environment to the real world, not only can we `push' people closer to a fabrication task, we can also add new ways of specifying and verifying functional requirements of a design.

For example, in an AR-equipped design environment, people wishing to build a bookshelf can sketch it to scale right where they wants to put it. Instead of designing purely out of intuition, they can now reference the real world context in which the bookshelf will eventually be installed. Such contextual cues might provide useful suggestions, such as maximum size allowed so that the bookshelf can fit in with surrounding furniture. Next, people can also use real books to show the system how much space it requires on the bookshelf. The system will compute the dimension of a book (e.g., calculating a bounding box); then people can specify how many books they want to put on the bookshelf, which sums up the total space needed. They can do this multiple times if they have books of very different sizes. They can also specify the weights of books using a similar method. Once cataloged by the system, the design is now constrained by the requirement to accommodate and support all the books of the users'; any further editing, if `violating' such constraints, will prompt the users to make adjustment in order to fix the problem. Finally, since the digital bookshelf is superimposed onto the real world, it can now guide people to actually fabricate the design. This is the part where hands-on making will be computationally supported. For example, if people want to reuse their spared IKEA parts, they can simply show the system each part, by which the system can compute a combination of these parts that will make the bookshelf, and further superimpose assembly instructions on top of the original design to assist people in putting the parts together.

 \xac{add a sketch here}

\textbf{Project goals} In this proposed project, my goal is to explore a full range of possibilities for AR to support an end-to-end design-fabrication task for everyday users. My specific sub-goals are as follows:

\xac{non-minor revision here}
\begin{itemize}
	\item Seamlessly integrating the previously separated design phase and fabrication phase: as AR blends digital and physical worlds, people can now perform design tasks in the real world context where the designed object will be placed, installed and used; they can also start making the object right away to test their design ideas rather than waiting for the design to be fully completed.
	\item Providing virtual references, instructions, feedbacks and suggestions (based on Chapter 5) to help people accomplish physical making tasks
	\item Digitalizing physical artifacts to enable a descriptive approach of `modeling by example'; leveraging the physical environment to help people organize their virtual design space.
	\item Enabling multi-modal interaction---combining gaze, gesture, motion and voice input to allow users to access and manipulate digital information while being able to focus on the main physical making task.
	\item Providing an environment that can support both freeform creation---where AR guides people to create physical forms of their design, and assembly-based tasks---where a design (e.g., a bookshelf) might consist of multiple components that need to be assembled and installed in a specific way.
\end{itemize}

The deliverable of this project would be an integral design environment based on an AR-enabled headset, that provides a number of value-added features to a range of making tasks. My hope is with an addition of such a system, real world context can better inform the functional aspects of a design, and people can do a better job getting their hands `dirty', and more importantly, become more willing and encouraged to participate in the making process.